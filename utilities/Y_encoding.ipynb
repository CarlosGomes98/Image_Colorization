{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io, color, transform\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.distance import cdist\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator\n",
    "from io import BytesIO\n",
    "from tensorflow.python.lib.io import file_io\n",
    "image_size = 128\n",
    "# image = np.random.rand(image_size, image_size, 3)\n",
    "# image[:, :, 0] = image[:, :, 0] * 100\n",
    "# image[:, :, 1:] = image[:, :, 1:] * 256 - 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(img_id, dir):\n",
    "    try:\n",
    "        img = load_img(dir + \"/\" + img_id, target_size=(image_size, image_size))\n",
    "        img = img_to_array(img)\n",
    "        return img\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.zeros((32, image_size, image_size, 3))\n",
    "directory = \"F:/Image_Colorization/data/Train_small/Train_small_1\"\n",
    "for index, image in enumerate(os.listdir(directory)[:32]):\n",
    "    encoded = np.load(directory+\"/\"+image)\n",
    "    bucketized = bucketize(encoded, rebalance)\n",
    "    new_image = np.zeros((image_size, image_size, 3))\n",
    "    new_image[:, :, 0] = encoded[:, :, 0]\n",
    "    new_image[:, :, 1:] = buckets[np.argmax(bucketized, axis=2)]\n",
    "    images[index] = new_image\n",
    "#io.imshow(color.lab2rgb(images[0]))\n",
    "#plt.show()\n",
    "#images = color.rgb2lab(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"F:/Image_Colorization/data/Train_small/Train_small_1\"\n",
    "buckets = np.load(\"pts_in_hull.npy\")\n",
    "batch = np.zeros((32, image_size, image_size, 2), dtype=int)\n",
    "for index, image_name in enumerate(os.listdir(directory)):\n",
    "    image = np.load(directory + \"/\" + image_name)\n",
    "    batch[index%32] = image\n",
    "    if (index + 1) % 32 == 0:\n",
    "        np.save(\"F:/Image_Colorization/data/Train_small_batches/batch_\"+str((index+1)//32), batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"F:/Image_Colorization/data/Train_small/Train_small_1\"\n",
    "buckets = np.load(\"pts_in_hull.npy\")\n",
    "rebalance = np.load(\"rebalance.npy\")\n",
    "X = np.empty((32, 128, 128, 1))\n",
    "Y = np.empty((32, 128*128, 313))\n",
    "batch = np.load(\"F:/Image_Colorization/data/Train_small_batches/batch_1.npy\")\n",
    "X = preprocess_and_return_X_batch(batch)\n",
    "Y = decode_bucketize_batch(batch, rebalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_return_X_batch(images):\n",
    "    X = images[:, :, :, 0]\n",
    "    X = X - 50\n",
    "    X = X/50\n",
    "    X = X.reshape(X.shape+(1,))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_bucketize_batch(images, rebalance):\n",
    "    identity = np.identity(313).astype(float)\n",
    "    bucketized = np.zeros((images.shape[0], image_size, image_size, 313))\n",
    "    bucketized = identity[images[... , 1]]\n",
    "    bucketized = bucketized * np.expand_dims(rebalance[np.argmax(bucketized, axis=3)], axis=3)\n",
    "    return bucketized.reshape(images.shape[0], image_size*image_size, 313)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(\"F:/Image_Colorization/data/Train_small_batches/batch_1.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, image in enumerate(os.listdir(directory)):\n",
    "    print(index, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"F:/Image_Colorization/data/Validation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = np.load(\"F:/Image_Colorization/data/Train_small/Train_small_1/Places365_test_00000006.npy\")\n",
    "bucketized = bucketize(encoded, rebalance)\n",
    "new_image = np.zeros((image_size, image_size, 3))\n",
    "new_image[:, :, 0] = encoded[:, :, 0]\n",
    "new_image[:, :, 1:] = buckets[np.argmax(bucketized, axis=2)]\n",
    "io.imshow(color.lab2rgb(new_image))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imshow(color.lab2rgb(images[2]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.empty((16, 128*128, 313))\n",
    "buckets = np.load(\"pts_in_hull.npy\")\n",
    "rebalance = np.load(\"rebalance.npy\")\n",
    "for index, image in enumerate(images):\n",
    "    Y[index,] = bucketize_gaussian(image[:, :, 1:], buckets, rebalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucketize_gaussian(imageAB, buckets, rebalance):\n",
    "    #calculate the distances from each pixel to each bucket\n",
    "    distances = np.zeros((image_size*image_size, buckets.shape[0]))\n",
    "    distances = cdist(imageAB.reshape(image_size*image_size, 2), buckets)\n",
    "    #find five shortest ones\n",
    "    shortest_distances_indices = np.argpartition(distances, 5)\n",
    "    five_shortest_distances_indices = shortest_distances_indices[:, :5]\n",
    "    not_five_shortest_distances_indices = np.argpartition(distances, 5)[:, 5:]\n",
    "    #zero the others\n",
    "    vertical_indices = np.arange(image_size*image_size)[:, np.newaxis]\n",
    "    distances[vertical_indices, not_five_shortest_distances_indices] = 0\n",
    "    #pass gaussian kernel and normalize 5 shortest distances\n",
    "    weights = np.exp(-distances[vertical_indices, five_shortest_distances_indices]**2/(2*5**2))\n",
    "    weights_norm = weights/np.sum(weights, axis=1, keepdims=True)\n",
    "    distances[vertical_indices, five_shortest_distances_indices] = weights_norm\n",
    "    distances = distances * np.expand_dims(rebalance[np.argmax(distances, axis=1)], axis=1)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = np.load(\"pts_in_hull.npy\")\n",
    "def bucketize_gaussian(image, buckets):\n",
    "#     get ab channels only\n",
    "    imagesAB = images[:, :, :, 1:]\n",
    "#     calculate the distances from each pixel to each bucket\n",
    "    distances = np.zeros((5*image_size*image_size, buckets.shape[0]))\n",
    "    distances = cdist(imagesAB.reshape(5*image_size*image_size, 2), buckets)\n",
    "#     find five shortest ones  \n",
    "    shortest_distances_indices = np.argpartition(distances, 5)\n",
    "    print(shortest_distances_indices)\n",
    "    five_shortest_distances_indices = shortest_distances_indices[:, :4]\n",
    "    not_five_shortest_distances_indices = np.argpartition(distances, 5)[:, 5:]\n",
    "#     zero the others\n",
    "    vertical_indices = np.arange(5*image_size*image_size)[:, np.newaxis]\n",
    "    distances[vertical_indices, not_five_shortest_distances_indices] = 0\n",
    "#     pass gaussian kernel and normalize 5 shortest distances\n",
    "    weights = np.exp(-distances[vertical_indices, five_shortest_distances_indices]**2/(2*5**2))\n",
    "    weights_norm = weights/np.sum(weights, axis=1, keepdims=True)\n",
    "    distances[vertical_indices, five_shortest_distances_indices] = weights_norm\n",
    "    return distances.reshape(5, image_size, image_size, 313)\n",
    "bucketize_gaussian(images, buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = np.load(\"pts_in_hull.npy\")\n",
    "def bucketize_gaussian_tf(inputs):\n",
    "    batch_size = inputs['batches']\n",
    "    imagesAB = inputs['images']\n",
    "    buckets = inputs['buckets']\n",
    "\n",
    "    #calculate the distances from each pixel to each bucket\n",
    "    distances = np.zeros((batch_size*image_size*image_size, buckets.shape[0]))\n",
    "    distances = cdist(imagesAB.reshape(batch_size*image_size*image_size, 2), buckets)\n",
    "    #find five shortest ones\n",
    "    shortest_distances_indices = np.argpartition(distances, 5)\n",
    "    five_shortest_distances_indices = shortest_distances_indices[:, :5]\n",
    "    not_five_shortest_distances_indices = np.argpartition(distances, 5)[:, 5:]\n",
    "    #zero the others\n",
    "    vertical_indices = np.arange(batch_size*image_size*image_size)[:, np.newaxis]\n",
    "    distances[vertical_indices, not_five_shortest_distances_indices] = 0\n",
    "    #pass gaussian kernel and normalize 5 shortest distances\n",
    "    weights = np.exp(-distances[vertical_indices, five_shortest_distances_indices]**2/(2*5**2))\n",
    "    weights_norm = weights/np.sum(weights, axis=1, keepdims=True)\n",
    "    distances[vertical_indices, five_shortest_distances_indices] = weights_norm\n",
    "    return distances.reshape(batch_size, image_size, image_size, 313)\n",
    "\n",
    "inputs_tensor = tf.convert_to_tensor(images[:, :, :, 1:])\n",
    "buckets_tensor = tf.convert_to_tensor(buckets)\n",
    "inputs = {'images': inputs_tensor, 'buckets': buckets_tensor, 'batches': 32}\n",
    "# image = np.zeros((128, 128, 314))\n",
    "# image[:, :, 0] = images[1, :, :, 0]\n",
    "image[:, :, 1:] = bucketize_gaussian(images[1, :, :, 1:], buckets, 1)\n",
    "# np.save(\"image.npy\", image)\n",
    "imageToRecover = np.load(\"image.npy\")\n",
    "imageRecover = np.zeros((128, 128, 3))\n",
    "imageRecover[:, :, 0] = imageToRecover[:, :, 0]\n",
    "imageRecover[:, :, 1:] = buckets[np.argmax(imageToRecover[:, :, 1:], axis=2)]\n",
    "io.imshow(color.lab2rgb(imageRecover))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = np.load(\"pts_in_hull.npy\")\n",
    "def bucketize_gaussian(imagesAB, buckets, batch_size):\n",
    "    #calculate the distances from each pixel to each bucket\n",
    "    distances = np.zeros((batch_size*image_size*image_size, buckets.shape[0]))\n",
    "    distances = cdist(imagesAB.reshape(batch_size*image_size*image_size, 2), buckets)\n",
    "    #find five shortest ones\n",
    "    shortest_distances_indices = np.argpartition(distances, 5)\n",
    "    five_shortest_distances_indices = shortest_distances_indices[:, :5]\n",
    "    not_five_shortest_distances_indices = np.argpartition(distances, 5)[:, 5:]\n",
    "    #zero the others\n",
    "    vertical_indices = np.arange(batch_size*image_size*image_size)[:, np.newaxis]\n",
    "    distances[vertical_indices, not_five_shortest_distances_indices] = 0\n",
    "    #pass gaussian kernel and normalize 5 shortest distances\n",
    "    weights = np.exp(-distances[vertical_indices, five_shortest_distances_indices]**2/(2*5**2))\n",
    "    weights_norm = weights/np.sum(weights, axis=1, keepdims=True)\n",
    "    distances[vertical_indices, five_shortest_distances_indices] = weights_norm\n",
    "    return distances.reshape(batch_size, image_size, image_size, 313)\n",
    "\n",
    "# image = np.zeros((128, 128, 314))\n",
    "# image[:, :, 0] = images[1, :, :, 0]\n",
    "# image[:, :, 1:] = bucketize_gaussian(images[1, :, :, 1:], buckets, 1)\n",
    "# np.save(\"image.npy\", image)\n",
    "image_bucketized = bucketize_gaussian(images[1, :, :, 1:], buckets, 1)\n",
    "# np.save(\"image.npy\", image)\n",
    "#imageToRecover = np.load(\"image.npy\")\n",
    "imageRecover = np.zeros((128, 128, 3))\n",
    "imageRecover[:, :, 0] = images[1, :, :, 0]\n",
    "imageRecover[:, :, 1:] = buckets[np.argmax(images[1, :, :, 1:], axis=2)]\n",
    "io.imshow(color.lab2rgb(imageRecover))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = np.load(\"pts_in_hull.npy\")\n",
    "def bucketize_gaussian(imagesAB, buckets):\n",
    "    #calculate the distances from each pixel to each bucket\n",
    "    distances = np.zeros((image_size*image_size, buckets.shape[0]))\n",
    "    distances = cdist(imagesAB.reshape(image_size*image_size, 2), buckets)\n",
    "    #find five shortest ones\n",
    "    shortest_distances_indices = np.argpartition(distances, 5)\n",
    "    five_shortest_distances_indices = shortest_distances_indices[:, :5]\n",
    "    not_five_shortest_distances_indices = np.argpartition(distances, 5)[:, 5:]\n",
    "    #zero the others\n",
    "    vertical_indices = np.arange(image_size*image_size)[:, np.newaxis]\n",
    "    distances[vertical_indices, not_five_shortest_distances_indices] = 0\n",
    "    #pass gaussian kernel and normalize 5 shortest distances\n",
    "    weights = np.exp(-distances[vertical_indices, five_shortest_distances_indices]**2/(2*5**2))\n",
    "    weights_norm = weights/np.sum(weights, axis=1, keepdims=True)\n",
    "    distances[vertical_indices, five_shortest_distances_indices] = weights_norm\n",
    "    return distances.reshape(image_size, image_size, 313)\n",
    "\n",
    "image_bucketized = bucketize_gaussian(images[1, :, :, 1:], buckets)\n",
    "# np.save(\"image.npy\", image)\n",
    "#imageToRecover = np.load(\"image.npy\")\n",
    "imageRecover = np.zeros((128, 128, 3))\n",
    "imageRecover[:, :, 0] = images[1, :, :, 0]\n",
    "imageRecover[:, :, 1:] = buckets[np.argmax(image_bucketized, axis=2)]\n",
    "io.imshow(color.lab2rgb(imageRecover))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucketize(image, rebalance):\n",
    "    identity = np.identity(313).astype(float)\n",
    "    bucketized = np.zeros((image_size, image_size, 313))\n",
    "    bucketized = identity[image[:, :, 1]]\n",
    "    bucketized = bucketized * np.expand_dims(rebalance[np.argmax(bucketized, axis=2)], axis=2)\n",
    "    return bucketized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucketize_batch(images, rebalance):\n",
    "    identity = np.identity(313).astype(float)\n",
    "    bucketized = np.zeros((images.shape[0], image_size, image_size, 313))\n",
    "    bucketized = identity[images[... , 1]]\n",
    "    bucketized = bucketized * np.expand_dims(rebalance[np.argmax(bucketized, axis=3)], axis=3)\n",
    "    return bucketized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebalance = np.load(\"rebalance.npy\")\n",
    "image1 = np.load(\"F:/Image_Colorization/data/Train_small/Train_small_1/Places365_test_00000006.npy\")\n",
    "image2 = np.load(\"F:/Image_Colorization/data/Train_small/Train_small_1/Places365_test_00000007.npy\")\n",
    "images = np.stack((image1, image2))\n",
    "images = bucketize_batch(images, rebalance)\n",
    "imagesValues = np.max(images[0], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def closest_buckets(imageAB, buckets):\n",
    "    #calculate the distances from each pixel to each bucket\n",
    "    distances = np.zeros((image_size*image_size, 313))\n",
    "    distances = cdist(imageAB.reshape(image_size*image_size, 2), buckets)\n",
    "    #find closest one\n",
    "    shortest_distance_indices = np.argmin(distances, axis=1)\n",
    "    return shortest_distance_indices.reshape(image_size, image_size)\n",
    "\n",
    "# cl_bk = closest_buckets(images[8, :, :, 1:], buckets, 1)\n",
    "# image = np.zeros((128, 128, 314))\n",
    "# image[:, :, 0] = images[1, :, :, 0]\n",
    "# image[:, :, 1:] = bucketize_gaussian(images[1, :, :, 1:], buckets, 1)\n",
    "# np.save(\"image.npy\", image)\n",
    "# imageToRecover = np.load(\"image.npy\")\n",
    "# imageRecover = np.zeros((128, 128, 3))\n",
    "# imageRecover[:, :, 0] = imageToRecover[:, :, 0]\n",
    "# imageRecover[:, :, 1:] = buckets[np.argmax(imageToRecover[:, :, 1:], axis=2)]\n",
    "# io.imshow(color.lab2rgb(imageRecover))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_buckets_image(image, buckets):\n",
    "    closest = closest_buckets(image[:, :, 1:], buckets)\n",
    "    new_image = np.zeros((image_size, image_size, 2), dtype=int)\n",
    "    new_image[:, :, 0] = image[:, :, 0].astype(int)\n",
    "    new_image[:, :, 1] = closest\n",
    "    return new_image.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebalance = np.load(\"rebalance.npy\")\n",
    "buckets = np.load(\"pts_in_hull.npy\")\n",
    "encoded = encode_buckets_image(images[2], buckets)\n",
    "bucketized = bucketize(encoded, rebalance)\n",
    "new_image = np.zeros((image_size, image_size, 3))\n",
    "new_image[:, :, 0] = encoded[:, :, 0]\n",
    "new_image[:, :, 1:] = buckets[np.argmax(bucketized, axis=2)]\n",
    "io.imshow(color.lab2rgb(new_image))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = np.identity(3)\n",
    "b = np.zeros((2, 2, 2), dtype=int)\n",
    "b[0, 0, 0] = \n",
    "identity[b][0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketized = bucketize_gaussian(images, buckets)\n",
    "reverted = np.zeros((image_size, image_size, 3))\n",
    "reverted[:, :, 0] = images[1, :, :, 0]\n",
    "reverted[:, :, 1:] = buckets[np.argmax(bucketized[1], axis=2)]\n",
    "io.imshow(color.lab2rgb(reverted))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = np.arange(-135, 145, 10)\n",
    "# bins_to_colors = np.arange(-130, 140, 10)\n",
    "# bins_to_colors[0] = -128\n",
    "# bins_to_colors[-1] = 127\n",
    "# print(bins_to_colors)\n",
    "# bins = np.zeros((5, image_size, image_size))\n",
    "# binned = np.zeros((5, image_size, image_size, 676))\n",
    "# # image_colors_positived = images[:, :, :, 1:] + 133\n",
    "# image_colors_in_bins = np.digitize(images[:, :, :, 1:], colors)\n",
    "# image_colors_in_bins = image_colors_in_bins - 1\n",
    "# one_hot = np.eye(676)\n",
    "# bins = 26*image_colors_in_bins[:, :, :, 0] + image_colors_in_bins[:, :, :, 1]\n",
    "# binned[:, :, :] = one_hot[bins[:, :, :]]\n",
    "# print np.argwhere(binned[1]==1)[:, 2].reshape((image_size, image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverted_image = np.zeros((image_size, image_size, 3)).astype(int)\n",
    "# image_binned = np.argwhere(binned[2, :, :]==1)[:, 2].reshape((image_size, image_size))\n",
    "# reverted_image[:, :, 0] = images[2, :, :, 0]\n",
    "# reverted_image[:, :, 2] = np.mod(image_binned ,np.full((image_size, image_size), 26))\n",
    "# reverted_image[:, :, 1] = (image_binned - reverted_image[:, :, 2]) / 26\n",
    "\n",
    "\n",
    "# reverted_image[:, :, 1:] = bins_to_colors[reverted_image[:, :, 1:]]\n",
    "# reverted_image = reverted_image*1.0\n",
    "# io.imshow(color.lab2rgb(reverted_image))\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
