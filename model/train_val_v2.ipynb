{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "sCL4yz1C0bxg"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jrdRoZoHq27X"
   },
   "outputs": [],
   "source": [
    "#!pip install -q keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "q8RkvoB6UlqU"
   },
   "outputs": [],
   "source": [
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "mK4Ruxs6OMYI"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, UpSampling2D, Conv2D, Dense, Dropout, BatchNormalization, Flatten, Conv2DTranspose\n",
    "import os\n",
    "from keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator\n",
    "import numpy as np\n",
    "from skimage import io, color\n",
    "from keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, Callback\n",
    "\n",
    "image_size = 64\n",
    "image_path = \"data/\"\n",
    "def read_image(img_id, dir):\n",
    "    try:\n",
    "        img = load_img(dir + \"/\" + img_id, target_size=(image_size, image_size))\n",
    "        img = img_to_array(img)\n",
    "        return img\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def show_image(image):\n",
    "    plt.imshow(image/255.)\n",
    "    plt.show()\n",
    "\n",
    "def printOutput(file, output):\n",
    "    for y in range(256):\n",
    "        row = \"\"\n",
    "        for x in range(256):\n",
    "            row += str(output[y, x]) + \" \"\n",
    "        file.write(row + \"\\n\")\n",
    "    file.close()\n",
    "    \n",
    "def meanCenter(trainData, dataToCenter):\n",
    "  mean = np.mean(trainData, 0, dtype=np.float32)\n",
    "  mean[:, :, 1:] = 0 #center only the lightness channel, which is the input\n",
    "  return dataToCenter - mean\n",
    "\n",
    "'''\n",
    "X = []\n",
    "files = os.listdir(image_path + \"/Train/\")[:2000]\n",
    "for image in files:\n",
    "    img = read_image(image, image_path + \"/Train/\")\n",
    "    if not img is None:\n",
    "        img = np.array(img, dtype=np.float32)\n",
    "        X.append(img)\n",
    "\n",
    "print(len(X))\n",
    "X = np.array(X, dtype=np.float32)\n",
    "Xtrain = (1.0/255)*X\n",
    "Xtrain = color.rgb2lab(Xtrain)\n",
    "print(Xtrain.shape)\n",
    "Xtrain = meanCenter(Xtrain, Xtrain)\n",
    "'''\n",
    "\n",
    "test = []\n",
    "files = os.listdir(image_path + \"/Test/\")[:200]\n",
    "for image in files:\n",
    "    img = read_image(image, image_path + \"/Test/\")\n",
    "    if not img is None:\n",
    "        img = np.array(img, dtype=np.float32)\n",
    "        test.append(img)\n",
    "test = np.array(test, dtype=np.float32)\n",
    "\n",
    "test = test*(1.0/255)\n",
    "test = color.rgb2lab(test)\n",
    "#test = meanCenter(Xtrain, test)\n",
    "test = test[:, :, :, 0]\n",
    "test = test - 50\n",
    "test = test/100\n",
    "test = test.reshape(test.shape+(1,))\n",
    "\n",
    "'''\n",
    "#validation set\n",
    "validation = []\n",
    "files = os.listdir(image_path + \"/Validation/\")\n",
    "for image in files:\n",
    "    img = read_image(image, image_path + \"/Validation/\")\n",
    "    if not img is None:\n",
    "        img = np.array(img, dtype=np.float32)\n",
    "        validation.append(img)\n",
    "validation = np.array(validation, dtype=np.float32)\n",
    "\n",
    "validation = validation*(1.0/255)\n",
    "validation = color.rgb2lab(validation)\n",
    "#test = meanCenter(Xtrain, test)\n",
    "X_val = validation[:, :, :, 0]\n",
    "X_val = X_val.reshape(X_val.shape+(1,))\n",
    "Y_val = validation[:, :, :, 1:]/128\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "kcEh3X2QR8B7"
   },
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zsMkWHZCsVQ4"
   },
   "outputs": [],
   "source": [
    "def convLayer(input, filters, kernel_size,  stride=1):\n",
    "    return Conv2D(filters, kernel_size, padding=\"same\", activation=\"relu\", strides=stride)(input)\n",
    "\n",
    "input_shape = (image_size, image_size, 1)\n",
    "\n",
    "model_input = Input(shape = input_shape)\n",
    "\n",
    "model_output = convLayer(model_input, 64, (3, 3))\n",
    "model_output = convLayer(model_output, 64, (3, 3), stride=2)\n",
    "model_output = BatchNormalization()(model_output)\n",
    "\n",
    "model_output = convLayer(model_output, 128, (3, 3))\n",
    "model_output = convLayer(model_output, 128, (3, 3), stride=2)\n",
    "model_output = BatchNormalization()(model_output)\n",
    "\n",
    "model_output = convLayer(model_output, 256, (3, 3))\n",
    "model_output = convLayer(model_output, 256, (3, 3), stride=2)\n",
    "model_output = BatchNormalization()(model_output)\n",
    "\n",
    "model_output = convLayer(model_output, 512, (3, 3))\n",
    "model_output = convLayer(model_output, 512, (3, 3))\n",
    "model_output = BatchNormalization()(model_output)\n",
    "\n",
    "model_output = convLayer(model_output, 512, (3, 3))\n",
    "model_output = convLayer(model_output, 512, (3, 3))\n",
    "model_output = BatchNormalization()(model_output)\n",
    "\n",
    "model_output = UpSampling2D((2, 2))(model_output) #not sure if this or deconvolution\n",
    "model_output = convLayer(model_output, 256, (3, 3))\n",
    "model_output = BatchNormalization()(model_output)\n",
    "\n",
    "model_output = UpSampling2D((2, 2))(model_output) \n",
    "model_output = convLayer(model_output, 64, (3, 3))\n",
    "model_output = BatchNormalization()(model_output)\n",
    "\n",
    "model_output = UpSampling2D((2, 2))(model_output) \n",
    "model_output = Conv2D(2, (3, 3), activation=\"tanh\", padding=\"same\")(model_output)\n",
    "\n",
    "model = Model(inputs=model_input, outputs=model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "el0uOpPhufsf"
   },
   "outputs": [],
   "source": [
    "# model.load_weights(\"drive/app/output/my_model_weights2018-08-10 20:36.h5\")\n",
    "# if(not os.path.exists(\"/floyd/input/model/my_model_weights.h5\")):\n",
    "datagen = ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #samplewise_center=False,\n",
    "    shear_range=0.4,\n",
    "    zoom_range=0.4,\n",
    "    rotation_range=40,\n",
    "    horizontal_flip=True,\n",
    "    rescale=(1./255)\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=(1./255))\n",
    "\n",
    "batch_size = 64\n",
    "def batch_generator(batch_size):\n",
    "    for batch in datagen.flow_from_directory(image_path+\"/Train/\",\n",
    "                                             target_size=(image_size, image_size),\n",
    "                                             class_mode=\"input\",\n",
    "                                             batch_size = batch_size):\n",
    "        lab = color.rgb2lab(batch[0])\n",
    "        X = lab[:, :, :, 0]\n",
    "        X = X - 50\n",
    "        X = X/100\n",
    "        X = X.reshape(X.shape+(1,))\n",
    "        Y = lab[:, :, :, 1:] / 128\n",
    "        yield ([X, Y])\n",
    "        \n",
    "def val_batch_generator(batch_size):\n",
    "    for batch in datagen.flow_from_directory(image_path+\"/Validation/\",\n",
    "                                             target_size=(image_size, image_size),\n",
    "                                             class_mode=\"input\",\n",
    "                                             batch_size = batch_size):\n",
    "        lab = color.rgb2lab(batch[0])\n",
    "        X = lab[:, :, :, 0]\n",
    "        X = X - 50\n",
    "        X = X/100\n",
    "        X = X.reshape(X.shape+(1,))\n",
    "        Y = lab[:, :, :, 1:] / 128\n",
    "        yield ([X, Y])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "outputDate = now.strftime(\"%Y-%m-%d %H:%M\")\n",
    "os.chdir(\"output\")\n",
    "os.mkdir(outputDate)\n",
    "os.chdir(outputDate)\n",
    "\n",
    "class WeightsSaver(Callback):\n",
    "    def __init__(self, N):\n",
    "        self.N = N\n",
    "        self.batch = 0\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if self.batch % self.N == 0:\n",
    "            name = 'currentWeights.h5'\n",
    "            self.model.save_weights(name)\n",
    "        self.batch += 1\n",
    "        \n",
    "checkpoint = ModelCheckpoint(\"best.hdf5\",\n",
    "                            monitor=\"accuracy\",\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode=\"max\")\n",
    "\n",
    "every_20_batches = WeightsSaver(20)\n",
    "\n",
    "every_10 = ModelCheckpoint(\"latest.hdf5\",\n",
    "                          monitor=\"accuracy\",\n",
    "                          verbose=1,\n",
    "                          save_best_only=False,\n",
    "                          mode='auto',\n",
    "                          period=1)\n",
    "\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\".\")\n",
    "model.compile(loss='mean_squared_error',\n",
    "            optimizer=\"adam\",\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(batch_generator(batch_size), callbacks=[tensorboard, checkpoint, every_10, every_20_batches], epochs=1, steps_per_epoch=5132, validation_data=val_batch_generator(batch_size)) #5132 steps per epoch\n",
    "\n",
    "\n",
    "try:\n",
    "    model.save_weights(\"model_weights.h5\")\n",
    "# else:\n",
    "#     model.load_weights(\"/floyd/input/model/my_model_weights.h5\")\n",
    "except:\n",
    "    print(\"Could not save\")\n",
    "\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4qjs9LcKn0gF"
   },
   "outputs": [],
   "source": [
    "# model.load_weights(\"drive/app/output/my_model_weights2018-08-10 20:36.h5\")\n",
    "# if(not os.path.exists(\"/floyd/input/model/my_model_weights.h5\")):\n",
    "datagen = ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #samplewise_center=False,\n",
    "    shear_range=0.4,\n",
    "    zoom_range=0.4,\n",
    "    rotation_range=40,\n",
    "    horizontal_flip=True,\n",
    "    rescale=(1./255)\n",
    ")\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "def batch_generator(batch_size):\n",
    "    for batch in datagen.flow_from_directory(image_path+\"/Train/\",\n",
    "                                             target_size=(image_size, image_size),\n",
    "                                             class_mode=\"input\",\n",
    "                                             batch_size = batch_size):\n",
    "        lab = color.rgb2lab(batch[0])\n",
    "        X = lab[:, :, :, 0]\n",
    "        X = X.reshape(X.shape+(1,))\n",
    "        Y = lab[:, :, :, 1:] / 128\n",
    "        yield ([X, Y])\n",
    "\n",
    "def val_batch_generator(batch_size):\n",
    "    for batch in datagen.flow_from_directory(image_path+\"/Validation/\",\n",
    "                                         target_size=(image_size, image_size),\n",
    "                                         class_mode=\"input\",\n",
    "                                         batch_size = batch_size):\n",
    "        lab = color.rgb2lab(batch[0])\n",
    "        X = lab[:, :, :, 0]\n",
    "        X = X.reshape(X.shape+(1,))\n",
    "        Y = lab[:, :, :, 1:] / 128\n",
    "        yield ([X, Y])\n",
    "        \n",
    "model.summary()\n",
    "\n",
    "outputDate = now.strftime(\"%Y-%m-%d %H:%M\")\n",
    "os.chdir(\"output\")\n",
    "os.mkdir(outputDate)\n",
    "os.chdir(outputDate)\n",
    "\n",
    "class WeightsSaver(Callback):\n",
    "    def __init__(self, N):\n",
    "        self.N = N\n",
    "        self.batch = 0\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if self.batch % self.N == 0:\n",
    "            name = 'currentWeights.h5'\n",
    "            self.model.save_weights(name)\n",
    "        self.batch += 1\n",
    "        \n",
    "checkpoint = ModelCheckpoint(\"best.hdf5\",\n",
    "                            monitor=\"accuracy\",\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode=\"max\")\n",
    "\n",
    "every_20_batches = WeightsSaver(20)\n",
    "\n",
    "every_10 = ModelCheckpoint(\"latest.hdf5\",\n",
    "                          monitor=\"accuracy\",\n",
    "                          verbose=1,\n",
    "                          save_best_only=False,\n",
    "                          mode='auto',\n",
    "                          period=1)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\".\")\n",
    "\n",
    "\n",
    "model.load_weights(\"/content/drive/My Drive/app/output/2018-09-29 14:58/latest.hdf5\")#manually change this, i know, i know\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "            optimizer=\"adam\",\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(batch_generator(batch_size), callbacks=[tensorboard, checkpoint, every_10, every_20_batches], epochs=1, steps_per_epoch=5132, validation_data=val_batch_generator(batch_size)) #5132 steps per epoch\n",
    "\n",
    "\n",
    "try:\n",
    "    model.save_weights(\"model_weights.h5\")\n",
    "# else:\n",
    "#     model.load_weights(\"/floyd/input/model/my_model_weights.h5\")\n",
    "except:\n",
    "    print(\"Could not save\")\n",
    "\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zwEQdfSeOwEh"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"latest.hdf5\")\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "            optimizer=\"adam\",\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hdUzivJdHRLo"
   },
   "outputs": [],
   "source": [
    "# Test model\n",
    "output = model.predict(test)\n",
    "output = output * 128\n",
    "print(output.shape)\n",
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "    cur = np.zeros((image_size, image_size, 3))\n",
    "    cur[:,:,0] = test[i][:,:,0]\n",
    "    cur[:,:,1:] = output[i]\n",
    "    io.imsave(str(i) + \".png\", color.lab2rgb(cur))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_val v2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
