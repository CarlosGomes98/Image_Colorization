{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "lsywywo6psM1",
    "outputId": "e4bb73e1-5ab4-4937-af73-4441ad344421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpg: keybox '/tmp/tmp2dr1quqa/pubring.gpg' created\n",
      "gpg: /tmp/tmp2dr1quqa/trustdb.gpg: trustdb created\n",
      "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
      "gpg: Total number processed: 1\n",
      "gpg:               imported: 1\n",
      "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
      "^C\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Co6YuH0EU8sH"
   },
   "outputs": [],
   "source": [
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jrdRoZoHq27X"
   },
   "outputs": [],
   "source": [
    "!pip install -q keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "q8RkvoB6UlqU"
   },
   "outputs": [],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5204,
     "status": "error",
     "timestamp": 1535826845286,
     "user": {
      "displayName": "Carlos Gomes",
      "photoUrl": "//lh3.googleusercontent.com/-51p88zNAFrI/AAAAAAAAAAI/AAAAAAAAAVQ/vBs5_j4YoHg/s50-c-k-no/photo.jpg",
      "userId": "106115122602816439072"
     },
     "user_tz": -60
    },
    "id": "mK4Ruxs6OMYI",
    "outputId": "c7430df5-489f-438b-a3ce-a4faf9629e9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4669554468e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgb2lab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mX_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/color/colorconv.py\u001b[0m in \u001b[0;36mrgb2lab\u001b[0;34m(rgb, illuminant, observer)\u001b[0m\n\u001b[1;32m   1033\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0msupported\u001b[0m \u001b[0milluminants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m     \"\"\"\n\u001b[0;32m-> 1035\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mxyz2lab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb2xyz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0milluminant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/color/colorconv.py\u001b[0m in \u001b[0;36mrgb2xyz\u001b[0;34m(rgb)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;31m# Follow the algorithm from http://www.easyrgb.com/index.php\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[0;31m# except we don't multiply/divide by 100 in the conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_colorarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.04045\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.055\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1.055\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/color/colorconv.py\u001b[0m in \u001b[0;36m_prepare_colorarray\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    153\u001b[0m         msg = (\"the input array must be have a shape == (.., ..,[ ..,] 3)), \" +\n\u001b[1;32m    154\u001b[0m                \"got (\" + (\", \".join(map(str, arr.shape))) + \")\")\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_as_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: the input array must be have a shape == (.., ..,[ ..,] 3)), got (0)"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, UpSampling2D, Conv2D, Dense, Dropout, BatchNormalization, Flatten, Conv2DTranspose\n",
    "import os\n",
    "from keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator\n",
    "import numpy as np\n",
    "from skimage import io, color\n",
    "from keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "image_path = \"drive/app/input/256/\"\n",
    "\n",
    "def read_image(img_id, dir):\n",
    "    try:\n",
    "        img = load_img(dir + \"/\" + img_id, target_size=(256,256))\n",
    "        img = img_to_array(img)\n",
    "        return img\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def show_image(image):\n",
    "    plt.imshow(image/255.)\n",
    "    plt.show()\n",
    "\n",
    "def convLayer(input, filters, kernel_size,  stride=1):\n",
    "    return Conv2D(filters, kernel_size, padding=\"same\", activation=\"relu\", strides=stride)(input)\n",
    "\n",
    "def printOutput(file, output):\n",
    "    for y in range(256):\n",
    "        row = \"\"\n",
    "        for x in range(256):\n",
    "            row += str(output[y, x]) + \" \"\n",
    "        file.write(row + \"\\n\")\n",
    "    file.close()\n",
    "\n",
    "X = []\n",
    "files = os.listdir(image_path + \"/Train/\") #[:512]\n",
    "for image in files:\n",
    "    img = read_image(image, image_path)\n",
    "    if not img is None:\n",
    "        img = np.array(img, dtype=np.float32)\n",
    "        X.append(img)\n",
    "\n",
    "print(len(X))\n",
    "X = np.array(X, dtype=np.float32)\n",
    "Xtrain = (1.0/255)*X\n",
    "\n",
    "test = []\n",
    "files = os.listdir(image_path + \"/Test/\") #[512:522]\n",
    "for image in files:\n",
    "    img = read_image(image, image_path)\n",
    "    if not img is None:\n",
    "        img = np.array(img, dtype=np.float32)\n",
    "        test.append(img)\n",
    "test = np.array(test, dtype=np.float32)\n",
    "\n",
    "test = test*(1.0/255)\n",
    "test = color.rgb2lab(test)\n",
    "test = test.reshape(test.shape+(1,))\n",
    "X_val = X[-10:, :, :, 0]\n",
    "X_val = X_val.reshape(X_val.shape+(1,))\n",
    "Y_val = X[-10:, :, :, 1:]/128\n",
    "X = X[:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zsMkWHZCsVQ4"
   },
   "outputs": [],
   "source": [
    "input_shape = (256, 256, 1)\n",
    "\n",
    "model_input = Input(shape = input_shape)\n",
    "\n",
    "model_output = convLayer(model_input, 32, (3, 3))\n",
    "model_output = convLayer(model_output, 32, (3, 3), stride=2)\n",
    "\n",
    "model_output = convLayer(model_output, 64, (3, 3))\n",
    "model_output = convLayer(model_output, 64, (3, 3), stride=2)\n",
    "\n",
    "model_output = convLayer(model_output, 128, (3, 3))\n",
    "model_output = convLayer(model_output, 128, (3, 3), stride=2)\n",
    "\n",
    "model_output = convLayer(model_output, 256, (3, 3))\n",
    "model_output = convLayer(model_output, 256, (3, 3))\n",
    "\n",
    "model_output = convLayer(model_output, 256, (3, 3))\n",
    "model_output = convLayer(model_output, 256, (3, 3))\n",
    "\n",
    "model_output = Conv2DTranspose((2, 2))(model_output)\n",
    "model_output = convLayer(model_output, 128, (3, 3))\n",
    "\n",
    "model_output = Conv2DTranspose((2, 2))(model_output)\n",
    "model_output = convLayer(model_output, 64, (3, 3))\n",
    "\n",
    "model_output = Conv2DTranspose((2, 2))(model_output)\n",
    "\n",
    "model_output = Conv2D(2, (3, 3), activation=\"tanh\", padding=\"same\")(model_output)\n",
    "\n",
    "model = Model(inputs=model_input, outputs=model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "el0uOpPhufsf"
   },
   "outputs": [],
   "source": [
    "# model.load_weights(\"drive/app/output/my_model_weights2018-08-10 20:36.h5\")\n",
    "# if(not os.path.exists(\"/floyd/input/model/my_model_weights.h5\")):\n",
    "datagen = ImageDataGenerator(\n",
    "    shear_range=0.4,\n",
    "    zoom_range=0.4,\n",
    "    rotation_range=40,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "batch_size = 32\n",
    "def batch_generator(batch_size):\n",
    "    for batch in datagen.flow(Xtrain, batch_size = batch_size):\n",
    "        lab = color.rgb2lab(batch)\n",
    "        X = lab[:, :, :, 0]\n",
    "        X = X.reshape(X.shape+(1,))\n",
    "        Y = lab[:, :, :, 1:] / 128\n",
    "        yield ([X, Y])\n",
    "        \n",
    "def val_batch_generator(batch_size):\n",
    "    for batch in val_datagen.flow(Xtrain, batch_size = batch_size):\n",
    "        lab = color.rgb2lab(batch)\n",
    "        X = lab[:, :, :, 0]\n",
    "        X = X.reshape(X.shape+(1,))\n",
    "        Y = lab[:, :, :, 1:] / 128\n",
    "        yield ([X, Y])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "outputDate = now.strftime(\"%Y-%m-%d %H:%M\")\n",
    "os.chdir(\"drive/app/output\")\n",
    "os.mkdir(outputDate)\n",
    "os.chdir(outputDate)\n",
    "checkpoint = ModelCheckpoint(\"best.hdf5\",\n",
    "                            monitor=\"acc\",\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode=\"max\")\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\".\")\n",
    "model.compile(loss='mean_squared_error',\n",
    "            optimizer=\"rmsprop\",\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(batch_generator(batch_size), callbacks=[tensorboard, checkpoint], epochs=1000, steps_per_epoch=8, validation_data=(X_val, Y_val))\n",
    "\n",
    "\n",
    "try:\n",
    "    model.save_weights(\"model_weights.h5\")\n",
    "# else:\n",
    "#     model.load_weights(\"/floyd/input/model/my_model_weights.h5\")\n",
    "except:\n",
    "    print(\"Could not save\")\n",
    "\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hdUzivJdHRLo"
   },
   "outputs": [],
   "source": [
    "inputs = np.concatenate(test[:, :, :, 0], X_val)\n",
    "\n",
    "# Test model\n",
    "output = model.predict(inputs)\n",
    "output = output * 128\n",
    "print(output.shape)\n",
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "    cur = np.zeros((256, 256, 3))\n",
    "    cur[:,:,0] = inputs[i][:,:,0]\n",
    "    cur[:,:,1:] = output[i]\n",
    "    io.imsave(str(i) + \".png\", color.lab2rgb(cur))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Train_CNN_MSE.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
